{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Treinamento_Tacotron_PTBRV2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ODI651CWUdFs"
      ],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/etltda/colabs/blob/main/Copy_of_Treinamento_Tacotron_PTBRV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODI651CWUdFs"
      },
      "source": [
        "# **Colab de treinamento Tacotron 2 (PT-BR)**\n",
        "## Siga os passos, executando as células na ordem, para usar.\n",
        "---\n",
        "\n",
        "## [Notebook de síntese](https://colab.research.google.com/drive/1-XWvLVhD11ZFosHsEqLnhiF58y-LlQWh)\n",
        "\n",
        "---\n",
        "\n",
        "Código originalmente feito por Cookie para o Pony Preservation Project\n",
        "\n",
        "Organizado e simplificado por mega b#6696\n",
        "\n",
        "Suporte para acentuação e tradução por Cris140#6815\n",
        "\n",
        "Agradecimentos ao IBob012 pelos avisos e ajuda no final\n",
        "\n",
        "[Tacotron 2](https://github.com/NVIDIA/tacotron2)\n",
        "\n",
        "---\n",
        "\n",
        "## **Notas:**  \n",
        "#### Você pode encontrar dificuldades ao enviar arquivos (> 1 MB) se usar um navegador que não seja baseado em chromium.\n",
        "#### Erros podem ocorrer. Em caso de dúvidas, fale com a gente pelo [Server do Discord](https://discord.gg/SfAs9CjZRX)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparação"
      ],
      "metadata": {
        "id": "1mcEohGLalzo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75SFQOP_Wnpz",
        "cellView": "form"
      },
      "source": [
        "#@markdown # Verifique a GPU.\n",
        "#@markdown ---\n",
        "#@markdown #### Não é recomendado usar a placa **K80** (apesar de funcionar corretamente, é **demorada**). Resete o ambiente de execução para a configuração original para **obter outra placa**.\n",
        "\n",
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Anti-desconexão do Google Colab.\n",
        "#@markdown ---\n",
        "#@markdown #### Evita a desconexão automática. Mesmo assim, desconectará após **6 à 12 horas**.\n",
        "\n",
        "import IPython\n",
        "js_code = '''\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "'''\n",
        "display(IPython.display.Javascript(js_code))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "q1uBxHKNXZxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhZSeuWHoj6g"
      },
      "source": [
        "\n",
        "# Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6aq6vRzqEV9",
        "cellView": "form"
      },
      "source": [
        "#@markdown ## **1** Montar seu Google Drive.\n",
        "\n",
        "#Google Drive Authentication Token\n",
        "from google.colab import drive\n",
        "drive.mount('drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6zQ-DWo4lcs",
        "cellView": "form"
      },
      "source": [
        "%%capture\n",
        "#@markdown ## **2** Instalar Tacotron 2 e suas dependências.\n",
        "%tensorflow_version 1.x\n",
        "%cd /content/\n",
        "import os\n",
        "from os.path import exists\n",
        "import sys\n",
        "!pip install phonemizer\n",
        "!pip install ffmpeg-normalize\n",
        "!pip install git+https://github.com/wkentaro/gdown.git\n",
        "!git clone -q https://github.com/Cris140/tacotron2\n",
        "sys.path.append('tacotron2')\n",
        "%cd content/tacotron2\n",
        "!git clone -q --recursive https://github.com/SortAnon/hifi-gan\n",
        "sys.path.append('hifi-gan')\n",
        "!pip install git+https://github.com/Cris140/num2words\n",
        "!git submodule init\n",
        "!git submodule update\n",
        "!pip install -q unidecode tensorboardX\n",
        "!apt-get install pv\n",
        "!apt-get -qq install sox\n",
        "!apt-get install jq\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import IPython.display as ipd\n",
        "import json\n",
        "from layers import TacotronSTFT\n",
        "from audio_processing import griffin_lim\n",
        "from env import AttrDict\n",
        "from meldataset import mel_spectrogram, MAX_WAV_VALUE\n",
        "from models import Generator\n",
        "from denoiser import Denoiser\n",
        "import resampy\n",
        "import scipy.signal\n",
        "\n",
        "import os\n",
        "if os.getcwd() != '/content/tacotron2':\n",
        "    os.chdir('tacotron2')\n",
        "import time\n",
        "import argparse\n",
        "import math\n",
        "from numpy import finfo\n",
        "\n",
        "import torch\n",
        "from distributed import apply_gradient_allreduce\n",
        "import torch.distributed as dist\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from model import Tacotron2\n",
        "from data_utils import TextMelLoader, TextMelCollate\n",
        "from loss_function import Tacotron2Loss\n",
        "from logger import Tacotron2Logger\n",
        "from hparams import create_hparams\n",
        " \n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import layers\n",
        "from utils import load_wav_to_torch, load_filepaths_and_text\n",
        "from text import text_to_sequence\n",
        "from math import e\n",
        "#from tqdm import tqdm # Terminal\n",
        "#from tqdm import tqdm_notebook as tqdm # Legacy Notebook TQDM\n",
        "from tqdm.notebook import tqdm # Modern Notebook TQDM\n",
        "from distutils.dir_util import copy_tree\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "%cd /content/\n",
        "def get_hifigan(MODEL_ID, conf_name):\n",
        "    # Download HiFi-GAN\n",
        "    hifigan_pretrained_model = 'hifimodel_' + conf_name\n",
        "    #gdown.download(d+MODEL_ID, hifigan_pretrained_model, quiet=False)\n",
        "\n",
        "    if MODEL_ID == \"universal\":\n",
        "      !wget \"https://github.com/johnpaulbin/tacotron2/releases/download/Main/g_02500000\" -O $hifigan_pretrained_model\n",
        "    else:\n",
        "      !gdown --id \"$MODEL_ID\" -O $hifigan_pretrained_model\n",
        "\n",
        "    # Load HiFi-GAN\n",
        "    conf = os.path.join(\"hifi-gan\", conf_name + \".json\")\n",
        "    with open(conf) as f:\n",
        "        json_config = json.loads(f.read())\n",
        "    h = AttrDict(json_config)\n",
        "    torch.manual_seed(h.seed)\n",
        "    hifigan = Generator(h).to(torch.device(\"cuda\"))\n",
        "    state_dict_g = torch.load(hifigan_pretrained_model, map_location=torch.device(\"cuda\"))\n",
        "    hifigan.load_state_dict(state_dict_g[\"generator\"])\n",
        "    hifigan.eval()\n",
        "    hifigan.remove_weight_norm()\n",
        "    denoiser = Denoiser(hifigan, mode=\"normal\")\n",
        "    return hifigan, h, denoiser\n",
        " \n",
        "# Download character HiFi-GAN\n",
        "hifigan, h, denoiser = get_hifigan(\"universal\", \"config_v1\")\n",
        "# Download super-resolution HiFi-GAN\n",
        "hifigan_sr, h2, denoiser_sr = get_hifigan(\"14fOprFAIlCQkVRxsfInhEPG0n-xN4QOa\", \"config_32k\")\n",
        "\n",
        "%cd /content/tacotron2\n",
        "\n",
        "def download_from_google_drive(file_id, file_name):\n",
        "  # download a file from the Google Drive link\n",
        "  !rm -f ./cookie\n",
        "  !curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id={file_id}\" > /dev/null\n",
        "  confirm_text = !awk '/download/ {print $NF}' ./cookie\n",
        "  confirm_text = confirm_text[0]\n",
        "  !curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm={confirm_text}&id={file_id}\" -o {file_name}\n",
        "\n",
        "def create_mels():\n",
        "    print(\"Gerando Mels\")\n",
        "    stft = layers.TacotronSTFT(\n",
        "                hparams.filter_length, hparams.hop_length, hparams.win_length,\n",
        "                hparams.n_mel_channels, hparams.sampling_rate, hparams.mel_fmin,\n",
        "                hparams.mel_fmax)\n",
        "    def save_mel(filename):\n",
        "        audio, sampling_rate = load_wav_to_torch(filename)\n",
        "        if sampling_rate != stft.sampling_rate:\n",
        "            raise ValueError(\"{} {} SR não corresponde ao objetivo {} SR\".format(filename, \n",
        "                sampling_rate, stft.sampling_rate))\n",
        "        audio_norm = audio / hparams.max_wav_value\n",
        "        audio_norm = audio_norm.unsqueeze(0)\n",
        "        audio_norm = torch.autograd.Variable(audio_norm, requires_grad=False)\n",
        "        melspec = stft.mel_spectrogram(audio_norm)\n",
        "        melspec = torch.squeeze(melspec, 0).cpu().numpy()\n",
        "        np.save(filename.replace('.wav', ''), melspec)\n",
        "\n",
        "    import glob\n",
        "    wavs = glob.glob('wavs/*.wav')\n",
        "    for i in tqdm(wavs):\n",
        "        save_mel(i)\n",
        "\n",
        "\n",
        "def reduce_tensor(tensor, n_gpus):\n",
        "    rt = tensor.clone()\n",
        "    dist.all_reduce(rt, op=dist.reduce_op.SUM)\n",
        "    rt /= n_gpus\n",
        "    return rt\n",
        "\n",
        "\n",
        "def init_distributed(hparams, n_gpus, rank, group_name):\n",
        "    assert torch.cuda.is_available(), \"Distributed mode requires CUDA.\"\n",
        "    print(\"Initializing Distributed\")\n",
        "\n",
        "    # Set cuda device so everything is done on the right GPU.\n",
        "    torch.cuda.set_device(rank % torch.cuda.device_count())\n",
        "\n",
        "    # Initialize distributed communication\n",
        "    dist.init_process_group(\n",
        "        backend=hparams.dist_backend, init_method=hparams.dist_url,\n",
        "        world_size=n_gpus, rank=rank, group_name=group_name)\n",
        "\n",
        "    print(\"Done initializing distributed\")\n",
        "\n",
        "\n",
        "def prepare_dataloaders(hparams):\n",
        "    # Get data, data loaders and collate function ready\n",
        "    trainset = TextMelLoader(hparams.training_files, hparams)\n",
        "    valset = TextMelLoader(hparams.validation_files, hparams)\n",
        "    collate_fn = TextMelCollate(hparams.n_frames_per_step)\n",
        "\n",
        "    if hparams.distributed_run:\n",
        "        train_sampler = DistributedSampler(trainset)\n",
        "        shuffle = False\n",
        "    else:\n",
        "        train_sampler = None\n",
        "        shuffle = True\n",
        "\n",
        "    train_loader = DataLoader(trainset, num_workers=1, shuffle=shuffle,\n",
        "                              sampler=train_sampler,\n",
        "                              batch_size=hparams.batch_size, pin_memory=False,\n",
        "                              drop_last=True, collate_fn=collate_fn)\n",
        "    return train_loader, valset, collate_fn\n",
        "\n",
        "\n",
        "def prepare_directories_and_logger(output_directory, log_directory, rank):\n",
        "    if rank == 0:\n",
        "        if not os.path.isdir(output_directory):\n",
        "            os.makedirs(output_directory)\n",
        "            os.chmod(output_directory, 0o775)\n",
        "        logger = Tacotron2Logger(os.path.join(output_directory, log_directory))\n",
        "    else:\n",
        "        logger = None\n",
        "    return logger\n",
        "\n",
        "\n",
        "def load_model(hparams):\n",
        "    model = Tacotron2(hparams).cuda()\n",
        "    if hparams.fp16_run:\n",
        "        model.decoder.attention_layer.score_mask_value = finfo('float16').min\n",
        "\n",
        "    if hparams.distributed_run:\n",
        "        model = apply_gradient_allreduce(model)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def warm_start_model(checkpoint_path, model, ignore_layers):\n",
        "    assert os.path.isfile(checkpoint_path)\n",
        "    print(\"Warm starting model from checkpoint '{}'\".format(checkpoint_path))\n",
        "    checkpoint_dict = torch.load(checkpoint_path, map_location='cpu')\n",
        "    model_dict = checkpoint_dict['state_dict']\n",
        "    if len(ignore_layers) > 0:\n",
        "        model_dict = {k: v for k, v in model_dict.items()\n",
        "                      if k not in ignore_layers}\n",
        "        dummy_dict = model.state_dict()\n",
        "        dummy_dict.update(model_dict)\n",
        "        model_dict = dummy_dict\n",
        "    model.load_state_dict(model_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint_path, model, optimizer):\n",
        "    assert os.path.isfile(checkpoint_path)\n",
        "    print(\"Loading checkpoint '{}'\".format(checkpoint_path))\n",
        "    checkpoint_dict = torch.load(checkpoint_path, map_location='cpu')\n",
        "    model.load_state_dict(checkpoint_dict['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint_dict['optimizer'])\n",
        "    learning_rate = checkpoint_dict['learning_rate']\n",
        "    iteration = checkpoint_dict['iteration']\n",
        "    print(\"Loaded checkpoint '{}' from iteration {}\" .format(\n",
        "        checkpoint_path, iteration))\n",
        "    return model, optimizer, learning_rate, iteration\n",
        "\n",
        "def save_checkpoint(model, optimizer, learning_rate, iteration, filepath):\n",
        "    print(\"Saving model and optimizer state at iteration {} to {}\".format(\n",
        "        iteration, filepath))\n",
        "    try:\n",
        "        torch.save({'iteration': iteration,\n",
        "                'state_dict': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'learning_rate': learning_rate}, filepath)\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"interrupt received while saving, waiting for save to complete.\")\n",
        "        torch.save({'iteration': iteration,'state_dict': model.state_dict(),'optimizer': optimizer.state_dict(),'learning_rate': learning_rate}, filepath)\n",
        "    print(\"Model Saved\")\n",
        "\n",
        "def plot_alignment(alignment, info=None):\n",
        "    %matplotlib inline\n",
        "    fig, ax = plt.subplots(figsize=(int(alignment_graph_width/100), int(alignment_graph_height/100)))\n",
        "    im = ax.imshow(alignment, cmap='inferno', aspect='auto', origin='lower',\n",
        "                   interpolation='none')\n",
        "    ax.autoscale(enable=True, axis=\"y\", tight=True)\n",
        "    fig.colorbar(im, ax=ax)\n",
        "    xlabel = 'Decoder timestep'\n",
        "    if info is not None:\n",
        "        xlabel += '\\n\\n' + info\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel('Encoder timestep')\n",
        "    plt.tight_layout()\n",
        "    fig.canvas.draw()\n",
        "    plt.show()\n",
        "\n",
        "def validate(model, criterion, valset, iteration, batch_size, n_gpus,\n",
        "             collate_fn, logger, distributed_run, rank, epoch, start_eposh, learning_rate):\n",
        "    \"\"\"Handles all the validation scoring and printing\"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_sampler = DistributedSampler(valset) if distributed_run else None\n",
        "        val_loader = DataLoader(valset, sampler=val_sampler, num_workers=1,\n",
        "                                shuffle=False, batch_size=batch_size,\n",
        "                                pin_memory=False, collate_fn=collate_fn)\n",
        "\n",
        "        val_loss = 0.0\n",
        "        for i, batch in enumerate(val_loader):\n",
        "            x, y = model.parse_batch(batch)\n",
        "            y_pred = model(x)\n",
        "            loss = criterion(y_pred, y)\n",
        "            if distributed_run:\n",
        "                reduced_val_loss = reduce_tensor(loss.data, n_gpus).item()\n",
        "            else:\n",
        "                reduced_val_loss = loss.item()\n",
        "            val_loss += reduced_val_loss\n",
        "        val_loss = val_loss / (i + 1)\n",
        "\n",
        "    model.train()\n",
        "    if rank == 0:\n",
        "        print(\"Epoch: {} Validation loss {}: {:9f}  Time: {:.1f}m LR: {:.6f}\".format(epoch, iteration, val_loss,(time.perf_counter()-start_eposh)/60, learning_rate))\n",
        "        logger.log_validation(val_loss, model, y, y_pred, iteration)\n",
        "        if hparams.show_alignments:\n",
        "            %matplotlib inline\n",
        "            _, mel_outputs, gate_outputs, alignments = y_pred\n",
        "            idx = random.randint(0, alignments.size(0) - 1)\n",
        "            plot_alignment(alignments[idx].data.cpu().numpy().T)\n",
        "\n",
        "    dv = epoch/10\n",
        "    if dv.is_integer():\n",
        "      print(f\"Gerando amostra... \\n{sampletext}\")\n",
        "      for i in [x for x in sampletext.split(\"\\n\") if len(x)]:\n",
        "          if i[-1] != \";\": i=i+\";\" \n",
        "          with torch.no_grad():\n",
        "              sequence = np.array(text_to_sequence(i, ['basic_cleaners']))[None, :]\n",
        "              sequence = torch.autograd.Variable(torch.from_numpy(sequence)).cuda().long()\n",
        "              mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n",
        "              y_g_hat = hifigan(mel_outputs_postnet.float())\n",
        "              audio = y_g_hat.squeeze()\n",
        "              audio = audio * MAX_WAV_VALUE\n",
        "              audio_denoised = denoiser(audio.view(1, -1), strength=35)[:, 0]\n",
        " \n",
        "              # Resample to 32k\n",
        "              audio_denoised = audio_denoised.cpu().numpy().reshape(-1)\n",
        " \n",
        "              normalize = (MAX_WAV_VALUE / np.max(np.abs(audio_denoised))) ** 0.9\n",
        "              audio_denoised = audio_denoised * normalize\n",
        "              wave = resampy.resample(\n",
        "                  audio_denoised,\n",
        "                  h.sampling_rate,\n",
        "                  h2.sampling_rate,\n",
        "                  filter=\"sinc_window\",\n",
        "                  window=scipy.signal.windows.hann,\n",
        "                  num_zeros=8,\n",
        "              )\n",
        "              wave_out = wave.astype(np.int16)\n",
        " \n",
        "              # HiFi-GAN super-resolution\n",
        "              wave = wave / MAX_WAV_VALUE\n",
        "              wave = torch.FloatTensor(wave).to(torch.device(\"cuda\"))\n",
        "              new_mel = mel_spectrogram(\n",
        "                  wave.unsqueeze(0),\n",
        "                  h2.n_fft,\n",
        "                  h2.num_mels,\n",
        "                  h2.sampling_rate,\n",
        "                  h2.hop_size,\n",
        "                  h2.win_size,\n",
        "                  h2.fmin,\n",
        "                  h2.fmax,\n",
        "              )\n",
        "              y_g_hat2 = hifigan_sr(new_mel)\n",
        "              audio2 = y_g_hat2.squeeze()\n",
        "              audio2 = audio2 * MAX_WAV_VALUE\n",
        "              audio2_denoised = denoiser(audio2.view(1, -1), strength=35)[:, 0]\n",
        "                  \n",
        "              # High-pass filter, mixing and denormalizing\n",
        "              audio2_denoised = audio2_denoised.cpu().numpy().reshape(-1)\n",
        "              b = scipy.signal.firwin(\n",
        "                  101, cutoff=10500, fs=h2.sampling_rate, pass_zero=False\n",
        "              )\n",
        "              y = scipy.signal.lfilter(b, [1.0], audio2_denoised)\n",
        "              y *= 0\n",
        "              y_out = y.astype(np.int16)\n",
        "              y_padded = np.zeros(wave_out.shape)\n",
        "              y_padded[: y_out.shape[0]] = y_out\n",
        "              sr_mix = wave_out + y_padded\n",
        "              sr_mix = sr_mix / normalize\n",
        "\n",
        "              print(\"\")\n",
        "              ipd.display(ipd.Audio(sr_mix.astype(np.int16), rate=h2.sampling_rate))\n",
        "\n",
        "def train(output_directory, log_directory, checkpoint_path, warm_start, n_gpus,\n",
        "          rank, group_name, hparams, log_directory2):\n",
        "    \"\"\"Training and validation logging results to tensorboard and stdout\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "    output_directory (string): directory to save checkpoints\n",
        "    log_directory (string) directory to save tensorboard logs\n",
        "    checkpoint_path(string): checkpoint path\n",
        "    n_gpus (int): number of gpus\n",
        "    rank (int): rank of current gpu\n",
        "    hparams (object): comma separated list of \"name=value\" pairs.\n",
        "    \"\"\"\n",
        "    if hparams.distributed_run:\n",
        "        init_distributed(hparams, n_gpus, rank, group_name)\n",
        "\n",
        "    torch.manual_seed(hparams.seed)\n",
        "    torch.cuda.manual_seed(hparams.seed)\n",
        "\n",
        "    model = load_model(hparams)\n",
        "    learning_rate = hparams.learning_rate\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,\n",
        "                                 weight_decay=hparams.weight_decay)\n",
        "\n",
        "    if hparams.fp16_run:\n",
        "        from apex import amp\n",
        "        model, optimizer = amp.initialize(\n",
        "            model, optimizer, opt_level='O2')\n",
        "\n",
        "    if hparams.distributed_run:\n",
        "        model = apply_gradient_allreduce(model)\n",
        "\n",
        "    criterion = Tacotron2Loss()\n",
        "\n",
        "    logger = prepare_directories_and_logger(\n",
        "        output_directory, log_directory, rank)\n",
        "\n",
        "    train_loader, valset, collate_fn = prepare_dataloaders(hparams)\n",
        "\n",
        "    # Load checkpoint if one exists\n",
        "    iteration = 0\n",
        "    svcount = 0\n",
        "    epoch_offset = 0\n",
        "    if checkpoint_path is not None and os.path.isfile(checkpoint_path):\n",
        "        if warm_start:\n",
        "            model = warm_start_model(\n",
        "                checkpoint_path, model, hparams.ignore_layers)\n",
        "        else:\n",
        "            model, optimizer, _learning_rate, iteration = load_checkpoint(\n",
        "                checkpoint_path, model, optimizer)\n",
        "            if hparams.use_saved_learning_rate:\n",
        "                learning_rate = _learning_rate\n",
        "            iteration += 1  # next iteration is iteration + 1\n",
        "            epoch_offset = max(0, int(iteration / len(train_loader)))\n",
        "    elif modelo_base != \"Nenhum\":\n",
        "        raise FileNotFoundError(f\"Modelo '{checkpoint_path}' não encontrado.\")\n",
        "    \n",
        "    start_eposh = time.perf_counter()\n",
        "    learning_rate = 0.0\n",
        "    model.train()\n",
        "    is_overflow = False\n",
        "    # ================ MAIN TRAINNIG LOOP! ===================\n",
        "    for epoch in tqdm(range(epoch_offset, hparams.epochs)):\n",
        "        print(\"\\nStarting Epoch: {} Iteration: {}\".format(epoch, iteration))\n",
        "        start_eposh = time.perf_counter() # eposh is russian, not a typo\n",
        "        for i, batch in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
        "            start = time.perf_counter()\n",
        "            if iteration < hparams.decay_start: learning_rate = hparams.A_\n",
        "            else: iteration_adjusted = iteration - hparams.decay_start; learning_rate = (hparams.A_*(e**(-iteration_adjusted/hparams.B_))) + hparams.C_\n",
        "            learning_rate = max(hparams.min_learning_rate, learning_rate) # output the largest number\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = learning_rate\n",
        "\n",
        "            model.zero_grad()\n",
        "            x, y = model.parse_batch(batch)\n",
        "            y_pred = model(x)\n",
        "\n",
        "            loss = criterion(y_pred, y)\n",
        "            if hparams.distributed_run:\n",
        "                reduced_loss = reduce_tensor(loss.data, n_gpus).item()\n",
        "            else:\n",
        "                reduced_loss = loss.item()\n",
        "            if hparams.fp16_run:\n",
        "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                    scaled_loss.backward()\n",
        "            else:\n",
        "                loss.backward()\n",
        "\n",
        "            if hparams.fp16_run:\n",
        "                grad_norm = torch.nn.utils.clip_grad_norm_(\n",
        "                    amp.master_params(optimizer), hparams.grad_clip_thresh)\n",
        "                is_overflow = math.isnan(grad_norm)\n",
        "            else:\n",
        "                grad_norm = torch.nn.utils.clip_grad_norm_(\n",
        "                    model.parameters(), hparams.grad_clip_thresh)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            if not is_overflow and rank == 0:\n",
        "                duration = time.perf_counter() - start\n",
        "                logger.log_training(\n",
        "                    reduced_loss, grad_norm, learning_rate, duration, iteration)\n",
        "                #print(\"Batch {} loss {:.6f} Grad Norm {:.6f} Time {:.6f}\".format(iteration, reduced_loss, grad_norm, duration), end='\\r', flush=True)\n",
        "\n",
        "            iteration += 1\n",
        "        validate(model, criterion, valset, iteration,\n",
        "                 hparams.batch_size, n_gpus, collate_fn, logger,\n",
        "                 hparams.distributed_run, rank, epoch, start_eposh, learning_rate)\n",
        "        svcount += 1\n",
        "        if svcount == saving_interval:\n",
        "          svcount = 0\n",
        "          save_checkpoint(model, optimizer, learning_rate, iteration, checkpoint_path)\n",
        "        if log_directory2 != None:\n",
        "            copy_tree(log_directory, log_directory2)\n",
        "def check_dataset(hparams):\n",
        "    from utils import load_wav_to_torch, load_filepaths_and_text\n",
        "    import os\n",
        "    import numpy as np\n",
        "    def check_arr(filelist_arr):\n",
        "        for i, file in enumerate(filelist_arr):\n",
        "            if len(file) > 2:\n",
        "                print(\"|\".join(file), \" possui múltplos '|', isso pode não ser um erro.\\n\")\n",
        "            if hparams.load_mel_from_disk and '.wav' in file[0]:\n",
        "                print(\"\\033[31m\\033[1m[AVISO]\", file[0], \" na filelist enquanto o esperado era .npy\\n\")\n",
        "            else:\n",
        "                if not hparams.load_mel_from_disk and '.npy' in file[0]:\n",
        "                    print(\"\\033[31m\\033[1m[AVISO]\", file[0], \" na filelist enquanto o esperado era .wav\\n\")\n",
        "            if (not os.path.exists(file[0])):\n",
        "                raise FileNotFoundError(f\"\\'{'|'.join(file)}\\' não existe. Verifique sua transcrição e seus áudios.\")\n",
        "            if len(file[1]) < 3:\n",
        "                print(f\"\\033[34m\\033[1m[info]{'|'.join(file)} não tem texto ou é muito curto.\\n\")\n",
        "            if not ((file[1].strip())[-1] in r\"!?,.;:\"):\n",
        "                print(f\"\\033[34m\\033[1m[info]{'|'.join(file)} não possui pontuação final.\\n\")\n",
        "            mel_length = 1\n",
        "            if hparams.load_mel_from_disk and '.npy' in file[0]:\n",
        "                melspec = torch.from_numpy(np.load(file[0], allow_pickle=True))\n",
        "                mel_length = melspec.shape[1]\n",
        "            if mel_length == 0:\n",
        "                print(f\"\\033[33m\\033[1m[AVISO]{'|'.join(file)} tem 0s de duração.\\n\")\n",
        "\n",
        "    print(\"Checando arquivos de treinamento\")\n",
        "    audiopaths_and_text = load_filepaths_and_text(hparams.training_files) # get split lines from training_files text file.\n",
        "    check_arr(audiopaths_and_text)\n",
        "    print(\"Checando arquivos de validação\")\n",
        "    audiopaths_and_text = load_filepaths_and_text(hparams.validation_files) # get split lines from validation_files text file.\n",
        "    check_arr(audiopaths_and_text)\n",
        "    print(\"\\033[32m\\033[1mChecagem finalizada\")\n",
        "n_gpus=1\n",
        "rank=0\n",
        "group_name=None\n",
        "\n",
        "# ---- DEFAULT PARAMETERS DEFINED HERE ----\n",
        "hparams = create_hparams()\n",
        "model_filename = 'current_model'\n",
        "hparams.training_files = \"filelists/clipper_train_filelist.txt\"\n",
        "hparams.validation_files = \"filelists/clipper_val_filelist.txt\"\n",
        "#hparams.use_mmi=True,          # not used in this notebook\n",
        "#hparams.use_gaf=True,          # not used in this notebook\n",
        "#hparams.max_gaf=0.5,           # not used in this notebook\n",
        "#hparams.drop_frame_rate = 0.2  # not used in this notebook\n",
        "hparams.p_attention_dropout=0.1\n",
        "hparams.p_decoder_dropout=0.1\n",
        "hparams.decay_start = 15000\n",
        "hparams.A_ = 5e-4\n",
        "hparams.B_ = 8000\n",
        "hparams.C_ = 0\n",
        "hparams.min_learning_rate = 1e-5\n",
        "generate_mels = True\n",
        "hparams.show_alignments = True\n",
        "alignment_graph_height = 600\n",
        "alignment_graph_width = 1000\n",
        "hparams.batch_size = 32\n",
        "hparams.load_mel_from_disk = True\n",
        "hparams.epochs = 10000\n",
        "hparams.sampling_rate = 22050\n",
        "hparams.max_decoder_steps = 3000 # Max Duration\n",
        "hparams.gate_threshold = 0.5 # Model must be 50% sure the clip is over before ending generation\n",
        "torch.backends.cudnn.enabled = hparams.cudnn_enabled\n",
        "torch.backends.cudnn.benchmark = hparams.cudnn_benchmark\n",
        "output_directory = '/content/drive/My Drive/colab/outdir' # Location to save Checkpoints\n",
        "log_directory = '/content/tacotron2/logs' # Location to save Log files locally\n",
        "log_directory2 = '/content/drive/My Drive/colab/logs' # Location to copy log files (done at the end of each epoch to cut down on I/O)\n",
        "checkpoint_path = output_directory+(r'/')+model_filename\n",
        "\n",
        "# ---- Replace .wav with .npy in filelists ----\n",
        "!sed -i -- 's,.wav|,.npy|,g' filelists/*.txt\n",
        "!sed -i -- 's,.wav|,.npy|,g' {hparams.training_files}\n",
        "!sed -i -- 's,.wav|,.npy|,g' {hparams.validation_files}\n",
        "# ---- Replace .wav with .npy in filelists ----\n",
        "\n",
        "%cd /content/tacotron2\n",
        "\n",
        "data_path = 'wavs'\n",
        "!mkdir {data_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## **3** Fazer upload dos **áudios**.\n",
        "#@markdown ---\n",
        "#@markdown #### Os áudios podem estar compactados em um **arquivo ZIP** (recomendado) ou soltos.\n",
        "#@markdown #### Você também pode fazer o upload manualmente do ZIP/pasta e inserir o caminho no campo abaixo, ou importar seus áudios do Drive, inserindo o caminho no modelo \"/content/drive/My Drive/seu_arquivo\". Caso queira fazer **upload na própria célula, deixe o campo vazio**.\n",
        "drive_path = \"\" #@param {type: \"string\"}\n",
        "\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "import wave\n",
        "import shutil\n",
        "import datetime\n",
        "\n",
        "if os.listdir('/content/tacotron2/wavs/'):\n",
        "  !rm /content/tacotron2/wavs/*\n",
        "\n",
        "with open('/content/audios.sh', 'w') as rsh:\n",
        "    rsh.write('''\\\n",
        "for file in /content/tacotron2/wavs/*.wav\n",
        "do\n",
        "    ffmpeg -y -i \"$file\" -ar 22050 /content/tempwav/srtmp.wav -loglevel error\n",
        "    sox /content/tempwav/srtmp.wav  -c 1 /content/tempwav/ntmp.wav norm -0.1\n",
        "    sox /content/tempwav/ntmp.wav /content/tempwav/ctmp.wav silence 1 0.05 0.1% reverse silence 1 0.05 0.1% reverse\n",
        "    ffmpeg -y -i /content/tempwav/ctmp.wav -c copy -fflags +bitexact -flags:v +bitexact -flags:a +bitexact -ar 22050 /content/tempwav/comiocudequemtalendo.wav -loglevel error\n",
        "    rm \"$file\"\n",
        "    mv /content/tempwav/comiocudequemtalendo.wav \"$file\"\n",
        "    rm /content/tempwav/*\n",
        "done\n",
        "''')\n",
        "\n",
        "%cd /content/tacotron2/wavs\n",
        "\n",
        "drive_path = drive_path.strip()\n",
        "\n",
        "if drive_path:\n",
        "  if os.path.exists(drive_path):\n",
        "    print(f\"\\n\\033[34m\\033[1mÁudios importados do Drive.\\n\\033[90m\")\n",
        "    if zipfile.is_zipfile(drive_path):\n",
        "      !unzip -q -j \"$drive_path\" -d /content/tacotron2/wavs\n",
        "\n",
        "    else:\n",
        "      fp = drive_path + \"/.\"\n",
        "      !cp -a \"$fp\" \"/content/tacotron2/wavs\"\n",
        "  else:\n",
        "    print(f\"\\n\\033[33m\\033[1m[AVISO] Caminho {drive_path} não encontrado, verifique erros e tente novamente.\")\n",
        "    print(f\"\\n\\033[34m\\033[1mFaça upload da sua dataset(áudios)...\")\n",
        "    uploaded = files.upload()\n",
        "else:\n",
        "  print(f\"\\n\\033[34m\\033[1mFaça upload da sua dataset(áudios)...\")\n",
        "  uploaded = files.upload()\n",
        "\n",
        "  for fn in uploaded.keys():\n",
        "    if zipfile.is_zipfile(fn):\n",
        "      !unzip -q -j \"$fn\" -d /content/tacotron2/wavs\n",
        "      !rm \"$fn\"\n",
        "\n",
        "if os.path.exists(\"/content/tacotron2/wavs/wavs\"):\n",
        "    for file in os.listdir(\"/content/tacotron2/wavs/wavs\"):\n",
        "      !mv /content/tacotron2/wavs/wavs/\"$file\"  /content/tacotron2/wavs/\"$file\"\n",
        "!rm /content/tacotron2/wavs/list.txt\n",
        "\n",
        "print(f\"\\n\\033[37mNormalizando, removendo metadados e checando áudios...\")\n",
        "!mkdir /content/tempwav\n",
        "!bash /content/audios.sh\n",
        "\n",
        "totalduration = 0\n",
        "for file_name in [x for x in os.listdir() if os.path.isfile(x)]:\n",
        "    with wave.open(file_name, \"rb\") as wave_file:\n",
        "        frames = wave_file.getnframes()\n",
        "        rate = wave_file.getframerate()\n",
        "        duration = frames / float(rate)\n",
        "        totalduration += duration\n",
        "\n",
        "        if duration >= 12:\n",
        "          print(f\"\\n\\033[33m\\033[1m[AVISO] {file_name} tem mais de 12 segundos. Falta de RAM pode\" \n",
        "                \" ocorrer em um batch size alto!\")\n",
        "\n",
        "wav_count = len(os.listdir(\"/content/tacotron2/wavs\"))\n",
        "print(f\"\\n{wav_count} áudios processados. Duração total: {str(datetime.timedelta(seconds=round(totalduration, 0)))}\\n\")\n",
        "\n",
        "shutil.make_archive(\"/content/processedwavs\", 'zip', '/content/tacotron2/wavs')\n",
        "files.download('/content/processedwavs.zip')\n",
        "\n",
        "print(\"\\n\\033[32m\\033[1mTudo pronto, prossiga.\")"
      ],
      "metadata": {
        "id": "j18Q4ku-oL0J",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## **4** Fazer upload da **transcrição**,\n",
        "#@markdown A transcrição deve ser um **arquivo TXT** formatado em UTF-8 sem BOM.\n",
        "%cd /content/tacotron2/filelists/\n",
        "!rm /content/tacotron2/filelists/list.txt\n",
        "\n",
        "print(\"\\n\\033[34m\\033[1mFaça upload da sua transcrição(list)...\")\n",
        "listfn, length = files.upload().popitem()\n",
        "\n",
        "if listfn != \"list.txt\":\n",
        "  !mv \"$listfn\" list.txt\n",
        "%cd /content/tacotron2/\n",
        "print(\"\\n\\033[32m\\033[1mTudo pronto, prossiga.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "CHtQAgFfIDJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP1trdpN_jV6",
        "cellView": "form"
      },
      "source": [
        "import os\n",
        "import os.path\n",
        "from pathlib import Path\n",
        "from itertools import chain\n",
        "from glob import glob\n",
        "#@markdown ## **5** Configurar os parâmetros do modelo.\n",
        "#@markdown ---\n",
        "#@markdown ####  Nome desejado para o modelo\n",
        "model_filename = \"\" #@param {type: \"string\"}\n",
        "Training_file = \"/content/tacotron2/filelists/list.txt\"\n",
        "hparams.training_files = Training_file\n",
        "hparams.validation_files = Training_file\n",
        "# hparams to Tune\n",
        "#hparams.use_mmi=True,          # not used in this notebook\n",
        "#hparams.use_gaf=True,          # not used in this notebook\n",
        "#hparams.max_gaf=0.5,           # not used in this notebook\n",
        "#hparams.drop_frame_rate = 0.2  # not used in this notebook\n",
        "hparams.p_attention_dropout=0.1\n",
        "hparams.p_decoder_dropout=0.1\n",
        "\n",
        "hparams.B_ = 8000                   # Decay Rate\n",
        "hparams.C_ = 0                      # Shift learning rate equation by this value\n",
        "hparams.min_learning_rate = 1e-5    # Min Learning Rate\n",
        "\n",
        "# Quality of Life\n",
        "generate_mels = True\n",
        "hparams.show_alignments = True\n",
        "alignment_graph_height = 600\n",
        "alignment_graph_width = 1000\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Tamanho do batch. Marque a caixa caso deseje que o código calcule o valor ideal automaticamente \n",
        "auto_batch_size = True #@param{type:\"boolean\"}\n",
        "hparams.batch_size =  18 #@param {type: \"integer\"}\n",
        "\n",
        "if auto_batch_size:\n",
        "  import subprocess\n",
        "  gpu_check = subprocess.check_output(\"nvidia-smi -L\", shell=True)\n",
        "  if \"K80\" in str(gpu_check):\n",
        "      hparams.batch_size = 14 if wav_count >= 144 else math.ceil(wav_count / 10.295714)\n",
        "  else:\n",
        "      hparams.batch_size = 18 if wav_count >= 144 else math.ceil(wav_count / 8)\n",
        "  print(f\"Batch size definido como {hparams.batch_size}\")\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Calcular Learning Rate ideal automaticamente (recomendado)\n",
        "# Learning Rate             # https://www.desmos.com/calculator/ptgcz4vzsw / http://boards.4channel.org/mlp/thread/34778298#p34789030\n",
        "hparams.decay_start = 15000         # wait till decay_start to start decaying learning rate\n",
        "autocalculate_learning_rate = True #@param {type:\"boolean\"}\n",
        "\n",
        "if autocalculate_learning_rate:\n",
        "  hparams.A_ = 0.001*(hparams.batch_size/256)**0.5 # Start/Max Learning Rate\n",
        "  print(f\"Learning Rate definido como {hparams.A_}\")\n",
        "else:\n",
        "  hparams.A_ = 5e-4\n",
        "\n",
        "hparams.load_mel_from_disk = True\n",
        " # Layers to reset (None by default, other than foreign languages this param can be ignored)\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Epochs de treinamento (não é recomendado mudar)\n",
        "hparams.epochs =  350#@param {type: \"integer\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Intervalo de Epochs para salvamento (não é recomendado mudar)\n",
        "saving_interval =  5#@param {type: \"integer\"}\n",
        "\n",
        "torch.backends.cudnn.enabled = hparams.cudnn_enabled\n",
        "torch.backends.cudnn.benchmark = hparams.cudnn_benchmark\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Onde salvar seu modelo no seu Drive\n",
        "output_directory = '/content/drive/My Drive/colab/outdir' #@param {type: \"string\"}\n",
        "log_directory = '/content/tacotron2/logs' # Location to save Log files locally\n",
        "log_directory2 = None # Location to copy log files (done at the end of each epoch to cut down on I/O)\n",
        "checkpoint_path = output_directory+(r'/')+model_filename\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ####Usar Warm start? Se for continuar treinando de um checkpoint, desative.\n",
        "warm_start = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ####  Escolha um modelo base para um alinhamento mais rápido (extremamente recomendado)\n",
        "if not os.path.exists(output_directory):\n",
        "    os.makedirs(output_directory)\n",
        "modelo_base = \"Zenyatta\" #@param [\"Felipe\", \"Zenyatta\", \"Nenhum\"]\n",
        "ids = {\"Felipe\": \"1--WWc4jqhtj9diANDpJazKnCh9g99mPd\", \"Zenyatta\": \"1-02A_qDM9Q7XI74jVO5UYKf4rKXD30V8\"}\n",
        "status_arquivo = os.path.isfile(checkpoint_path)\n",
        "if modelo_base != \"Nenhum\":\n",
        "    if status_arquivo == True:\n",
        "      print(\"\\n\\033[33m\\033[1m[Aviso] Já existe um arquivo com esse nome no seu drive. Se quiser utilizar o modelo base terá de apagar/renomear esse arquivo\")  \n",
        "    else:\n",
        "      print(f\"Baixando Modelo {modelo_base} em {checkpoint_path}\")\n",
        "      !gdown --id {ids[modelo_base]} -O \"$checkpoint_path\"\n",
        "#@markdown ---"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2-xc6EcACWc",
        "cellView": "form"
      },
      "source": [
        "#@markdown ## **6** Converter WAVs em espectogramas Mel e checar arquivos.\n",
        "import re\n",
        "import num2words\n",
        "import sys\n",
        "from contextlib import redirect_stdout\n",
        "import fileinput\n",
        "\n",
        "with open('/content/tacotron2/filelists/list.txt', 'r') as f:  \n",
        "    new_text = '\\n'.join([line.strip() for line in f.read().split('\\n') if line.strip()])\n",
        "    with open('/content/tacotron2/filelists/list.txt', 'w') as n:  \n",
        "      n.write(new_text)\n",
        "\n",
        "f_input = open('/content/tacotron2/filelists/list.txt','r')\n",
        "text = f_input.readlines()\n",
        "#print(text)\n",
        "text2 = len(text)\n",
        "textmacaca = \"\"\n",
        "#print(text2)\n",
        "for number in range(0,text2):\n",
        " macaca = number\n",
        " if(str(macaca) + \".wav\") in (text[number]):\n",
        "   pass\n",
        " else:\n",
        "  textmacaca = str(text[number])\n",
        "  textmacaca2 = textmacaca.split(\"|\")\n",
        "  try:\n",
        "    textmacaca2[1] = re.sub(r\"(\\d+)\", lambda x: num2words.num2words(int(x.group(0)), lang='pt_BR'), textmacaca2[1],)\n",
        "  except IndexError:\n",
        "    replace = textmacaca.replace('\\n', '')\n",
        "    raise Exception(f\"A linha '{replace}' está com problema, revise.\")\n",
        "  #print(textmacaca2[1])\n",
        "  text[number]  = (str(textmacaca2[0] + \"|\" + textmacaca2[1].lower()))\n",
        "  #print(text[number])\n",
        "\n",
        "  #print(text[number])\n",
        "textfinal = \" \"\n",
        "for number in range(text2):\n",
        " textfinal += text[number]\n",
        "textfinal = textfinal.replace('[','')\n",
        "textfinal = textfinal.replace(\"',\",'')\n",
        "textfinal = textfinal.replace(\"'\",'')\n",
        "textfinal = textfinal.replace(']','')\n",
        "textfinal = textfinal.replace('\\\\n','\\n')\n",
        "textfinal = textfinal.replace(' wavs','wavs')\n",
        "t = textfinal\n",
        "\"\".join([s for s in t.strip().splitlines(True) if s.strip()])\n",
        "print(textfinal, file=open(\"/content/tacotron2/filelists/list1.txt\", \"a\"))\n",
        "\n",
        "\n",
        "!rm /content/tacotron2/filelists/list.txt\n",
        "!mv /content/tacotron2/filelists/list1.txt /content/tacotron2/filelists/list.txt\n",
        "if generate_mels:\n",
        "    create_mels()\n",
        "\n",
        "print(\"Checando por arquivos faltando\")\n",
        "# ---- Replace .wav with .npy in filelists ----\n",
        "!sed -i -- 's,.wav|,.npy|,g' {hparams.training_files}; sed -i -- 's,.wav|,.npy|,g' {hparams.validation_files}\n",
        "\n",
        "check_dataset(hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqIk1dIuCqhx",
        "cellView": "form"
      },
      "source": [
        "#@markdown # **7** Começar treinamento (finalmente).\n",
        "#@markdown ---\n",
        "#@markdown #### Texto no qual vão ser geradas as amostras de áudio do modelo. Um texto muito grande pode ser demorado e difícil de gerar, e um muito pequeno pode não demonstrar muito bem o modelo, então escolha bem.\n",
        "sampletext = \"Jogador, você falou pra mim que mora na primeira esquerda depois do tratamento de esgoto. Jogador, pelo amor de Deus maluco, cadê essa esquerda que eu não acho mano?\" #@param {type: \"string\"}\n",
        "print('FP16 Run:', hparams.fp16_run)\n",
        "print('Dynamic Loss Scaling:', hparams.dynamic_loss_scaling)\n",
        "print('Distributed Run:', hparams.distributed_run)\n",
        "print('cuDNN Enabled:', hparams.cudnn_enabled)\n",
        "print('cuDNN Benchmark:', hparams.cudnn_benchmark)\n",
        "train(output_directory, log_directory, checkpoint_path,\n",
        "      warm_start, n_gpus, rank, group_name, hparams, log_directory2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4ql3OWWPKZv"
      },
      "source": [
        "# **Apontamentos finais**\n",
        "\n",
        "## Treinamento bom se parece com isso aqui:\n",
        "![img.png](https://media.discordapp.net/attachments/835971020569051216/851469553355587614/download_2.png)\n",
        "\n",
        "## Depois de treinar seu modelo bonitinho cheiroso, você pode testá-lo no [Notebook de síntese](https://colab.research.google.com/drive/1-XWvLVhD11ZFosHsEqLnhiF58y-LlQWh)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taNL0MBTqAOm"
      },
      "source": [
        "# Alguns erros e suas soluções:\n",
        "\n",
        "![img.png](https://media.discordapp.net/attachments/841732367962210344/889163051314602014/Screenshot_107.png?width=924&height=218)\n",
        "\n",
        "\"CUDA out of memory\" é quando o seu batch size é alto demais pra o GPU dar conta. Vai ser necessário diminuir ou verificar se nos seus arquivos tem algum audio muito longo(acima de 12 segundos).\n",
        "As vezes mesmo dimnuindo até 1 o erro persiste. Nesse caso, redefina o ambiente para a configuração padrão.\n",
        "\n",
        "---\n",
        "\n",
        "![img.png](https://media.discordapp.net/attachments/841732367962210344/889158394441769010/Screenshot_106.png?width=924&height=348)\n",
        "\n",
        "\"list index out of range\" é quando sua transcrição possui linhas vazias(geralmente no final). Remova a(s) linha(s), exclua o arquivo defeituoso do colab, faça upload da versão corrigida e rode a etapa 4 novamente.\n",
        "Outro erro desse tipo é Cannot load file containing pickled data, que também significa que tem uma linha vazia na transcrição. A diferença é que esse em particular ocorre durante o treinamento.\n",
        "\n",
        "---\n",
        "\n",
        "![img.png](https://media.discordapp.net/attachments/841732367962210344/889042673602813952/unknown.png?width=652&height=469)\n",
        "\n",
        "\"shape is invalid for input size\" é quando um ou mais áudios que você colocou não são stereo. Converta os áudios para a configuração correta (22hz PCM Uncompressed Mono) em algum programa, e então redefina o ambiente para a configuração original e faça o upload novamente.\n",
        "\n",
        "---\n",
        "\n",
        "![img.png](https://media.discordapp.net/attachments/841732367962210344/888658737332637706/unknown.png?width=919&height=432)\n",
        "\n",
        "O erro que me aterrorizou quando eu queria treinar o Chills. \"No such file or directory: '\\uffefwavs/1.npy'\" é causado quando a sua lista não está em UTF-8 without BOM. Pra solucionar isso, coloque a formatação correta no arquivo usando algum editor de texto. Notepad++ é uma boa opção, mas você pode encontrar no Google outros programas.\n",
        "\n",
        "---\n",
        "\n",
        "Então, é isso. Esses são os erros mais comuns. Se você não entendeu como se soluciona alguma das coisas ou apareceu pra você um erro que não tá descrito aqui, pergunta pra gente, a gente não morde. https://discord.gg/SfAs9CjZRX\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## **Rascunho, não mexe grrr**\n",
        "#@markdown ---\n",
        "#@markdown #### Os áudios podem estar compactados em um **arquivo ZIP** (recomendado) ou soltos.\n",
        "#@markdown #### Você também pode fazer o upload manualmente do ZIP/pasta e inserir o caminho no campo abaixo, ou importar seus áudios do Drive, inserindo o caminho no modelo \"/content/drive/My Drive/seu_arquivo\". Caso queira fazer **upload na própria célula, deixe o campo vazio**.\n",
        "drive_path = \"\" #@param {type: \"string\"}\n",
        "\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "import wave\n",
        "import shutil\n",
        "import datetime\n",
        "\n",
        "!rm /content/tacotron2/wavs/*\n",
        "\n",
        "with open('/content/audios.sh', 'w') as rsh:\n",
        "    rsh.write('''\\\n",
        "for file in /content/tacotron2/wavs/*.wav\n",
        "do\n",
        "    sox \"$file\" -c 1 /content/tempwav/ntmp.wav norm -0.1\n",
        "    sox /content/tempwav/ntmp.wav /content/tempwav/ctmp.wav silence 1 0.05 0.1% reverse silence 1 0.05 0.1% reverse\n",
        "    ffmpeg -y -i /content/tempwav/ctmp.wav -c copy -fflags +bitexact -flags:v +bitexact -flags:a +bitexact /content/tempwav/comiocudequemtalendo.wav -loglevel error\n",
        "    rm \"$file\"\n",
        "    mv /content/tempwav/comiocudequemtalendo.wav \"$file\"\n",
        "    rm /content/tempwav/*\n",
        "done\n",
        "''')\n",
        "\n",
        "%cd /content/tacotron2/wavs\n",
        "\n",
        "drive_path = drive_path.strip()\n",
        "\n",
        "if drive_path:\n",
        "  if os.path.exists(drive_path):\n",
        "    print(f\"\\n\\033[34m\\033[1mÁudios importados do Drive.\\n\\033[90m\")\n",
        "    if zipfile.is_zipfile(drive_path):\n",
        "      !unzip -q -j \"$drive_path\" -d /content/tacotron2/wavs\n",
        "    else:\n",
        "      fp = drive_path + \"/.\"\n",
        "      !cp -a \"$fp\" \"/content/tacotron2/wavs\"\n",
        "  else:\n",
        "    print(f\"\\n\\033[33m\\033[1m[AVISO] Caminho {drive_path} não encontrado, verifique erros e tente novamente.\")\n",
        "    print(f\"\\n\\033[34m\\033[1mFaça upload da sua dataset(áudios)...\")\n",
        "    uploaded = files.upload()\n",
        "else:\n",
        "  print(f\"\\n\\033[34m\\033[1mFaça upload da sua dataset(áudios)...\")\n",
        "  uploaded = files.upload()\n",
        "\n",
        "  for fn in uploaded.keys():\n",
        "    if zipfile.is_zipfile(fn):\n",
        "      !unzip -q -j \"$fn\" -d /content/tacotron2/wavs\n",
        "      !rm \"$fn\"\n",
        "\n",
        "print(f\"\\n\\033[37mNormalizando, removendo metadados e checando áudios...\")\n",
        "!mkdir /content/tempwav\n",
        "!bash /content/audios.sh\n",
        "\n",
        "totalduration = 0\n",
        "for file_name in [x for x in os.listdir() if os.path.isfile(x)]:\n",
        "    with wave.open(file_name, \"rb\") as wave_file:\n",
        "        frames = wave_file.getnframes()\n",
        "        rate = wave_file.getframerate()\n",
        "        duration = frames / float(rate)\n",
        "        totalduration += duration\n",
        "\n",
        "        if duration >= 12:\n",
        "          print(f\"\\n\\033[33m\\033[1m[AVISO] {file_name} tem mais de 12 segundos. Falta de RAM pode\" \n",
        "                \" ocorrer em um batch size alto!\")\n",
        "\n",
        "wav_count = len(os.listdir(\"/content/tacotron2/wavs\"))\n",
        "print(f\"\\n{wav_count} áudios processados. Duração total: {str(datetime.timedelta(seconds=round(totalduration, 0)))}\\n\")\n",
        "\n",
        "shutil.make_archive(\"/content/procwavs\", 'zip', '/content/tacotron2/wavs')\n",
        "files.download('/content/procwavs.zip')\n",
        "\n",
        "print(\"\\n\\033[32m\\033[1mTudo pronto, prossiga.\")"
      ],
      "metadata": {
        "id": "H0uFzNTnWEcJ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}